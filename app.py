import streamlit as st
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import cv2

# --- é é¢åŸºæœ¬é…ç½® ---
st.set_page_config(page_title="AI è¬èƒ½æ•™å­¸å¯¦é©—å®¤", layout="wide")

# --- è¼‰å…¥é è¨“ç·´æ¨¡å‹ (ä½¿ç”¨å¿«å–) ---
@st.cache_resource
def load_resources():
    # CNN åˆ†é¡æ¨¡å‹ (MobileNet V2)
    cnn_net = hub.load("https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4")
    labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')
    with open(labels_path) as f:
        labels = f.read().splitlines()
    return cnn_net, labels

cnn_net, imagenet_labels = load_resources()

# --- å´é‚Šæ¬„æ§åˆ¶ ---
st.sidebar.title("ğŸ“ AI çµ‚æ¥µæ•™å®¤")
st.sidebar.markdown("è«‹é¸æ“‡ä½ æƒ³æ¢ç´¢çš„ AI æŠ€è¡“ï¼š")
main_category = st.sidebar.selectbox("æŠ€è¡“é¡åˆ¥", ["ğŸ–¼ï¸ CNN å½±åƒå°ˆå®¶", "â³ RNN åºåˆ—å¤§å¸«"])

# =================================================================
#                         ğŸ–¼ï¸ CNN å½±åƒå°ˆå®¶å€
# =================================================================
if main_category == "ğŸ–¼ï¸ CNN å½±åƒå°ˆå®¶":
    st.title("ğŸ–¼ï¸ CNNï¼šå¾åƒç´ åˆ°ç‰¹å¾µçš„å½±åƒè§£æ")
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”¢ æ•¸å­—èˆ‡ç†è«–", "ğŸ“¦ è¬ç‰©è¾¨è­˜èˆ‡ç†±åŠ›åœ–", "ğŸ‘¤ äººè‡‰åµæ¸¬", "ğŸ‘¥ äººè‡‰èº«åˆ†æ¯”å°"])

    # --- Tab 1: æ•¸å­—èˆ‡ç†è«– ---
    with tab1:
        st.subheader("ğŸ’¡ CNN ç†è«–ï¼šåœ–ç‰‡å³çŸ©é™£")
        up_digit = st.file_uploader("ä¸Šå‚³æ•¸å­—ç…§ç‰‡...", type=['png','jpg'], key="d1")
        if up_digit:
            img = Image.open(up_digit).convert('L').resize((28, 28))
            img_arr = np.array(img)
            col1, col2 = st.columns(2)
            with col1:
                st.image(img, caption="åŸå§‹å½±åƒ", width=150)
                st.write("å±€éƒ¨ 10x10 åƒç´ çŸ©é™£ï¼š")
                st.dataframe(img_arr[:10, :10])
            with col2:
                # å·ç©æå–ç†è«–
                kernel = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]]) # å‚ç›´é‚Šç·£æ¿¾é¡
                conv_res = cv2.filter2D(img_arr, -1, kernel)
                st.image(conv_res, caption="å·ç©å¾Œçš„ç‰¹å¾µæå–", width=150)
                st.info("ç†è«–ï¼šCNN ç”¨ã€æ¿¾é¡çŸ©é™£ã€æ»‘éåœ–ç‰‡ï¼Œå°‡é¡è‰²å·®ç•°è½‰åŒ–ç‚ºç·šæ¢ç‰¹å¾µã€‚")
        

    # --- Tab 2: è¬ç‰©è¾¨è­˜ + ç†±åŠ›åœ– ---
    with tab2:
        st.subheader("ğŸ“¦ è¬ç‰©è¾¨è­˜ï¼šAI åœ¨çœ‹å“ªè£¡ï¼Ÿ")
        up_obj = st.file_uploader("ä¸Šå‚³ç…§ç‰‡è¾¨è­˜...", type=['jpg','png','jpeg'], key="o1")
        if up_obj:
            raw_img = Image.open(up_obj).convert('RGB').resize((224, 224))
            img_tensor = tf.convert_to_tensor(np.array(raw_img, dtype=np.float32)/255.0)[tf.newaxis, ...]
            probs = cnn_net(img_tensor)
            top_idx = np.argsort(probs[0])[-1]
            
            c1, c2 = st.columns(2)
            with c1:
                st.image(raw_img, caption=f"è¾¨è­˜çµæœï¼š{imagenet_labels[top_idx]}", use_container_width=True)
            with c2:
                st.write("ğŸ”¥ **ç‰¹å¾µé—œæ³¨åœ– (Grad-CAM æ¨¡æ“¬)**")
                heatmap = np.random.rand(224, 224) 
                fig, ax = plt.subplots()
                ax.imshow(raw_img); ax.imshow(heatmap, cmap='jet', alpha=0.5); ax.axis('off')
                st.pyplot(fig)
                st.write("ç´…è‰²å€åŸŸä»£è¡¨ AI åˆ¤æ–·ç‰©é«”åˆ†é¡æ™‚ã€æœ€é—œæ³¨ã€çš„ç‰¹å¾µã€‚")
        

    # --- Tab 3: äººè‡‰åµæ¸¬ ---
    with tab3:
        st.subheader("ğŸ‘¤ äººè‡‰åµæ¸¬ï¼šå°‹æ‰¾å¹¾ä½•æ’åˆ—")
        up_f = st.file_uploader("ä¸Šå‚³åˆç…§...", type=['jpg','png'], key="f_det")
        if up_f:
            f_cv = cv2.cvtColor(np.array(Image.open(up_f)), cv2.COLOR_RGB2BGR)
            cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            faces = cascade.detectMultiScale(f_cv, 1.1, 4)
            for (x, y, w, h) in faces:
                cv2.rectangle(f_cv, (x, y), (x+w, y+h), (0, 255, 0), 4)
            st.image(cv2.cvtColor(f_cv, cv2.COLOR_BGR2RGB), caption=f"åµæ¸¬åˆ° {len(faces)} å¼µè‡‰")

    # --- Tab 4: äººè‡‰æ¯”å° ---
    with tab4:
        st.subheader("ğŸ‘¥ äººè‡‰æ¯”å°ï¼šç›¸åŒäººåˆ¤å®š")
        st.write("åŸç†ï¼šè¨ˆç®—å…©å¼µè‡‰çš„ã€128ç¶­ç‰¹å¾µæŒ‡ç´‹ã€è·é›¢ã€‚")
        c1, c2 = st.columns(2)
        f1 = c1.file_uploader("ç…§ç‰‡ A", type=['jpg','png'], key="fa")
        f2 = c2.file_uploader("ç…§ç‰‡ B", type=['jpg','png'], key="fb")
        if f1 and f2:
            dist = np.random.uniform(0.2, 0.8) # æ¨¡æ“¬è·é›¢
            st.metric("ç‰¹å¾µè·é›¢ (è¶Šå°è¶Šæ¥è¿‘)", f"{dist:.4f}")
            if dist < 0.5: st.success("âœ… åˆ¤å®šï¼šé«˜æ©Ÿç‡ç‚ºåŒä¸€äºº")
            else: st.error("âŒ åˆ¤å®šï¼šä¸åŒäºº")

# =================================================================
#                         â³ RNN åºåˆ—å¤§å¸«å€
# =================================================================
elif main_category == "â³ RNN åºåˆ—å¤§å¸«":
    st.title("â³ RNNï¼šç†è§£æ™‚é–“èˆ‡èªæ„åºåˆ—")
    tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ è‚¡å¸‚é æ¸¬ (è¶¨å‹¢è¨˜æ†¶)", "ğŸ’¬ æƒ…æ„Ÿåˆ†æ (èƒ½é‡ç´¯ç©)", "ğŸŒ èªè¨€ç¿»è­¯ (ç·¨ç¢¼è§£ç¢¼)"])

    if 'rnn_vec' not in st.session_state: st.session_state.rnn_vec = np.zeros(10)

    # --- Tab 1: è‚¡å¸‚é æ¸¬ ---
    with tab1:
        st.subheader("ğŸ“ˆ è‚¡å¸‚èˆ‡æ™‚é–“åºåˆ—ç†è«–")
        st.write("ç†è«–ï¼šRNN é€é Hidden State è¨˜ä½æ˜¨å¤©çš„æ–œç‡ï¼Œä»¥æ­¤æ¨æ–·æ˜å¤©çš„ä½ç½®ã€‚")
        trend = st.selectbox("è¨­å®šè‚¡å¸‚æ°›åœ", ["çœ‹æ¼² ğŸš€", "çœ‹è·Œ ğŸ“‰", "éš¨æ©Ÿ ğŸ²"])
        
        fig, ax = plt.subplots(figsize=(8, 4))
        data = np.cumsum(np.random.randn(50) * 0.1 + (0.1 if "çœ‹æ¼²" in trend else -0.1 if "çœ‹è·Œ" in trend else 0))
        ax.plot(data, label="æ­·å²è¨˜æ†¶")
        ax.plot(range(50, 60), [data[-1] + (data[-1]-data[-2])*i for i in range(1, 11)], '--r', label="RNN é æ¸¬æœªä¾†")
        ax.legend(); st.pyplot(fig)
        

    # --- Tab 2: æƒ…æ„Ÿåˆ†æ ---
    with tab2:
        st.subheader("ğŸ’¬ æƒ…æ„Ÿåˆ†æï¼šèªæ„èƒ½é‡è¡¨")
        sentence = st.text_input("è¼¸å…¥å¥å­ (å¦‚: The food is good but service is bad):", "I love this")
        words = sentence.split()
        scores = []
        cur = 0
        for w in words:
            if w.lower() in ['bad', 'not', 'no']: cur -= 1
            elif w.lower() in ['love', 'good', 'happy']: cur += 1
            scores.append(cur)
        
        st.write("AI è…¦è¢‹è£¡çš„ã€æƒ…ç·’ç´¯ç©ã€éç¨‹ï¼š")
        fig, ax = plt.subplots(figsize=(8, 3))
        ax.step(range(len(words)), scores, where='post', marker='o', color='green')
        ax.set_xticks(range(len(words))); ax.set_xticklabels(words)
        st.pyplot(fig)
        

    # --- Tab 3: èªè¨€ç¿»è­¯ ---
    with tab3:
        st.subheader("ğŸŒ ç¿»è­¯ç†è«–ï¼šç·¨ç¢¼å™¨èˆ‡è§£ç¢¼å™¨")
        txt = st.text_input("è¼¸å…¥è‹±æ–‡ï¼š", "Hello world")
        c1, c2, c3 = st.columns([2, 1, 2])
        with c1: 
            st.info(f"ğŸ“¥ **Encoder**\nå°‡ '{txt}' å£“ç¸®æˆå‘é‡")
        with c2:
            st.write("â¡ï¸ **Vector**")
            st.write(np.random.rand(4).round(2))
        with c3:
            st.success("ğŸ“¤ **Decoder**\nè¼¸å‡ºï¼šä½ å¥½ä¸–ç•Œ")
        

# é å°¾ï¼šæ‰‹å‹•æ¸…é™¤
if st.sidebar.button("ğŸ§¼ æ¸…é™¤æ‰€æœ‰å¯¦é©—æ•¸æ“š"):
    st.session_state.clear()
    st.rerun()
